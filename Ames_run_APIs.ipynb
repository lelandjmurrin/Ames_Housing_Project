{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Ames_Functions import * #imports OSMR, get_geoapify, get_dist, locator, find_min_dist, load_state_pkl, save_state_pkl, EDA_report, etc.\n",
    "\n",
    "from geopy import Nominatim\n",
    "\n",
    "import pickle\n",
    "\n",
    "import os\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House Latlongs Lookup Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2n/5k95xl754cb_szsgjkmj33k80000gn/T/ipykernel_74387/473993362.py:2: DtypeWarning: Columns (36,40,81,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_RE_latest = pd.read_csv(\"data/Ames_Real_Estate_Data_Latest.csv\")\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DummyRegressor from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GradientBoostingRegressor from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GridSearchCV from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DummyRegressor from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GradientBoostingRegressor from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GridSearchCV from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DummyRegressor from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GradientBoostingRegressor from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GridSearchCV from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DummyRegressor from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeRegressor from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GradientBoostingRegressor from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/lelandmurrin/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator GridSearchCV from version 1.0.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Loading Datasets\n",
    "df_RE_latest = pd.read_csv(\"data/Ames_Real_Estate_Data_Latest.csv\")\n",
    "df_EssentialLatLong = pd.read_csv(\"data/df_EssentialLatLong_v2.csv\")\n",
    "\n",
    "#2021\n",
    "df_dist_time_all2021 = load_state_pkl()['2021dfs_for_feature_engineering'][0]\n",
    "df_RE_latlongs2021 = load_state_pkl()['df_RE_latlong2021'][0]\n",
    "\n",
    "#2019\n",
    "df_dist_time_all2019 = load_state_pkl()['2019dfs_for_feature_engineering'][0]\n",
    "df_RE_latlongs2019 = load_state_pkl()['df_RE_latlong2019'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating and then storing Latlongs using Geoapify\n",
    "\n",
    "#2019\n",
    "df_RE_latlongs2019 = df_RE_latest.query('YrSold_YYYY == 2019').drop_duplicates()\n",
    "latlongs2019 = df_RE_latlongs2019.Prop_Addr.apply(lambda x: get_geoapify(x + \", Ames, Iowa\"))\n",
    "\n",
    "#2021\n",
    "df_RE_latlongs2021 = df_RE_latest.query('YrSold_YYYY == 2021').drop_duplicates()\n",
    "latlongs2021 = df_RE_latlongs2021.Prop_Addr.apply(lambda x: get_geoapify(x + \", Ames, Iowa\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "locator = Nominatim(user_agent=\"myGeocoder\")\n",
    "\n",
    "def create_cleanup_latlongs_csv(latlongs, filename, df_RE_latlongs):\n",
    "    # Checking Latlongs with reverse geocoding\n",
    "    s_address = latlongs.apply(lambda x: locator.reverse(x).raw['address'])\n",
    "\n",
    "    # Pulling just the road from the reverse lookup address\n",
    "    s_road = pd.json_normalize(s_address).road.fillna(\"Monroe Drive\")\n",
    "    s_road.to_frame()\n",
    "\n",
    "    # Adding latlongs to the housing dataframe\n",
    "    df_RE_latlongs = df_RE_latlongs.join(latlongs.str.split(\",\", expand = True).set_axis([\"Lat\", \"Long\"], axis = 1))\n",
    "\n",
    "    # Adding reverse_lookup_rd field to dataframe for comparison to PA-Strt for manual corrections. \n",
    "    # This allowed for identifying discrepancies in the reverse_lookup_addresses and addresses listed in the dataset\n",
    "    df_RE_latlongs['reverse_lookup_rd'] = s_road.values\n",
    "    mask = df_RE_latlongs.apply(lambda x: x[\"PA-Strt\"].lower() not in x.reverse_lookup_rd.lower(), axis = 1)\n",
    "    df_RE_latlongs.query('@mask')[[\"Prop_Addr\", \"reverse_lookup_rd\", \"Lat\", \"Long\"]].to_csv(filename)\n",
    "    return df_RE_latlongs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2021\n",
    "df_RE_latlongs2021 = create_cleanup_latlongs_csv(latlongs2021, \"df_RE_latlongs2021_corrections.csv\", df_RE_latlongs2021)\n",
    "\n",
    "#2019\n",
    "df_RE_latlongs2019 = create_cleanup_latlongs_csv(latlongs2019, \"df_RE_latlongs2019_corrections.csv\", df_RE_latlongs2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OthAc_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>288800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22958</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22959</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22960</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22961</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22962</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22963 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       OthAc_S\n",
       "0            0\n",
       "1            0\n",
       "2            0\n",
       "3       288800\n",
       "4            0\n",
       "...        ...\n",
       "22958        0\n",
       "22959        0\n",
       "22960        0\n",
       "22961        0\n",
       "22962        0\n",
       "\n",
       "[22963 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_RE_latest.filter(regex = \"Oth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MapRefNo</th>\n",
       "      <th>GeoRefNo</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Range</th>\n",
       "      <th>Prop_Addr</th>\n",
       "      <th>ZngCdPr</th>\n",
       "      <th>ZngCdSc</th>\n",
       "      <th>ZngOLPr</th>\n",
       "      <th>ZngOLSc</th>\n",
       "      <th>ClassPr_S</th>\n",
       "      <th>...</th>\n",
       "      <th>PA-StSfx</th>\n",
       "      <th>PA-PostD</th>\n",
       "      <th>PA-UnTyp</th>\n",
       "      <th>PA-UntNo</th>\n",
       "      <th>Date</th>\n",
       "      <th>Source</th>\n",
       "      <th>NmbrBRs</th>\n",
       "      <th>reverse_lookup_rd</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11371</th>\n",
       "      <td>906329170.0</td>\n",
       "      <td>906329170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5116 SPRINGBROOK CIR</td>\n",
       "      <td>FS-RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RESIDENTIAL</td>\n",
       "      <td>...</td>\n",
       "      <td>CIR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31-Mar-22</td>\n",
       "      <td>Ames City Assessor</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6th Street</td>\n",
       "      <td>42.028568</td>\n",
       "      <td>-93.687674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11373</th>\n",
       "      <td>906329180.0</td>\n",
       "      <td>906329180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5122 SPRINGBROOK CIR</td>\n",
       "      <td>FS-RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RESIDENTIAL</td>\n",
       "      <td>...</td>\n",
       "      <td>CIR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31-Mar-22</td>\n",
       "      <td>Ames City Assessor</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6th Street</td>\n",
       "      <td>42.028348</td>\n",
       "      <td>-93.687718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MapRefNo   GeoRefNo  Tier  Range             Prop_Addr ZngCdPr  \\\n",
       "11371  906329170.0  906329170     0      0  5116 SPRINGBROOK CIR   FS-RL   \n",
       "11373  906329180.0  906329180     0      0  5122 SPRINGBROOK CIR   FS-RL   \n",
       "\n",
       "      ZngCdSc ZngOLPr ZngOLSc    ClassPr_S  ... PA-StSfx PA-PostD  PA-UnTyp  \\\n",
       "11371     NaN     NaN     NaN  RESIDENTIAL  ...      CIR      NaN       NaN   \n",
       "11373     NaN     NaN     NaN  RESIDENTIAL  ...      CIR      NaN       NaN   \n",
       "\n",
       "       PA-UntNo       Date              Source NmbrBRs  reverse_lookup_rd  \\\n",
       "11371       NaN  31-Mar-22  Ames City Assessor     2.0         6th Street   \n",
       "11373       NaN  31-Mar-22  Ames City Assessor     2.0         6th Street   \n",
       "\n",
       "             Lat       Long  \n",
       "11371  42.028568 -93.687674  \n",
       "11373  42.028348 -93.687718  \n",
       "\n",
       "[2 rows x 94 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in manual corrections file\n",
    "\n",
    "def update_latlongs_corrections(filename, df_RE_latlongs):\n",
    "    df_latlong_corrections = pd.read_csv(filename, index_col = 0)\n",
    "\n",
    "    #updating corrections to the dataset\n",
    "    df_RE_latlongs.loc[df_latlong_corrections.index, [\"Lat\", \"Long\"]] = df_latlong_corrections[[\"Lat\", \"Long\"]]\n",
    "    return df_RE_latlongs\n",
    "\n",
    "#2021\n",
    "df_RE_latlongs2021 = update_latlongs_corrections(\"df_RE_latlongs2021_corrections.csv\", df_RE_latlongs2021)\n",
    "\n",
    "#2019\n",
    "df_RE_latlongs2019 = update_latlongs_corrections(\"df_RE_latlongs2019_corrections.csv\", df_RE_latlongs2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving latlongs dataframe to the master dictionary stored in Ames_notebook_state pkl file to use accross multiple notebooks\n",
    "\n",
    "save_state_pkl('df_RE_latlong2021',\n",
    "               df_RE_latlongs2021,\n",
    "               \"latlong lookup for 2021 using geoapify and reverse lookup using nominatim with corrections done by hand\"\n",
    "               )\n",
    "\n",
    "save_state_pkl('df_RE_latlong2019',\n",
    "               df_RE_latlongs2019,\n",
    "               \"latlong lookup for 2019 using geoapify and reverse lookup using nominatim with corrections done by hand\"\n",
    "               )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driving time Lookups Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding closest business per service to each house and creating dataframe containing that information (df_subset)\n",
    "\n",
    "def create_df_subset (df_RE_latlongs, df_EssentialLatLong):\n",
    "    #the same code is found inside the Ames_Functions file, but returns df_subset with extra processing via pivot etc.\n",
    "    df_cross = df_RE_latlongs.join(df_EssentialLatLong, how = \"cross\", lsuffix = '_house', rsuffix = \"_biz\")\n",
    "    df_cross[\"dist\"] = df_cross.apply(lambda x: get_dist(np.array([x.Lat_house, x.Long_house]), np.array([x.Lat_biz, x.Long_biz])), axis = 1)\n",
    "    df_subset = df_cross.loc[df_cross.groupby([\"Service\", \"SaleID\"]).dist.idxmin()]\n",
    "    return df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell takes a while to run (1hour+)\n",
    "\n",
    "#Looking up drive times/distances for the closest businesses per service to each house and storing them in from_biz dictionary\n",
    "\n",
    "def drive_time_dist_lookups(df_subset):\n",
    "    from_biz = {}\n",
    "    OSMR_list = df_subset.Service.unique()\n",
    "\n",
    "    for i in OSMR_list:\n",
    "        from_biz[i] = df_subset.query(f\"Service == '{i}'\").apply(lambda x: OSMR(x.Lat_biz, x.Long_biz, x.Lat_house, x.Long_house), axis = 1)\n",
    "        \n",
    "    return pd.DataFrame(from_biz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_driv_time_final_dict(from_biz_final, df_subset, df_RE_latlongs):\n",
    "        from_biz_stacked = from_biz_final.stack().reset_index().set_axis([\"df_subset_index\", \"Service\", \"time_dist\"], axis = 1)\n",
    "\n",
    "        from_biz_temp = from_biz_stacked.join(from_biz_stacked\n",
    "                                                .apply(lambda x: f\"{x.time_dist[0][0]}, {x.time_dist[0][1]}\", axis = 1)\n",
    "                                                .str.split(\", \", expand = True)\n",
    "                                                .set_axis([\"time_secs\", \"driving_dist_meters\"], axis = 1)\n",
    "                                                .apply(lambda x: x.astype(float))\n",
    "                                                ).drop(\"time_dist\", axis = 1)\n",
    "\n",
    "        driv_final_dict = {}\n",
    "\n",
    "        for k, f in zip([\"from_time\", \"from_driv\", \"dist\"], [\"time_secs\", \"driving_dist_meters\", \"dist\"]):\n",
    "                driv_final_dict[k] = (df_subset\n",
    "                                        .join(from_biz_temp.set_index(\"df_subset_index\"), rsuffix = \"_driv\")\n",
    "                                        .query(\"Service == Service_driv\")\n",
    "                                        .drop(\"Service_driv\", axis = 1)\n",
    "                                        .pivot(index = [\"SaleID\", \"Lat_house\", \"Long_house\"], columns = \"Service\", values = f)\n",
    "                                        .reset_index()\n",
    "                                        .set_index(\"SaleID\").join(df_subset[[\"SaleID\", \"SalePrice\"]].drop_duplicates().set_index(\"SaleID\").SalePrice)\n",
    "                                )\n",
    "\n",
    "        driv_final_dict['df_min_time'] = (df_subset.join(from_biz_temp.set_index(\"df_subset_index\"), rsuffix = \"_driv\")\n",
    "            .drop(\"Service_driv\", axis = 1)\n",
    "            .pivot(index = [\"SaleID\"], columns = \"Service\", values = \"time_secs\")\n",
    "            .reset_index()\n",
    "            .set_index(\"SaleID\")\n",
    "            .add_suffix(\"_time\")\n",
    "            )\n",
    "        \n",
    "        driv_final_dict['df_min_dist'] = find_min_dist(df_RE_latlongs, df_EssentialLatLong).set_index(\"SaleID\")\n",
    "                             \n",
    "\n",
    "        return driv_final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df_for_feature_engineering(driv_final_dict, df_subset):\n",
    "    def service_pivot (left_df, right_df, v):\n",
    "        return left_df.copy().join(right_df.pivot(columns = \"Service\", index = \"SaleID\", values = v).add_suffix(\"_\" + v))\n",
    "\n",
    "    df_min_time = driv_final_dict['df_min_time']\n",
    "    df_min_dist = driv_final_dict['df_min_dist']\n",
    "\n",
    "    return (df_min_dist\n",
    "                .join(df_min_time)\n",
    "                .pipe(service_pivot, df_subset, \"Lat_biz\")\n",
    "                .pipe(service_pivot, df_subset, \"Long_biz\")\n",
    "                .drop(\"SalePrice\", axis = 1)\n",
    "                .join(df_min_dist.SalePrice)\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating 2021 dfs after API drive time/distance lookups in preparation for feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating df_subset\n",
    "df_subset2021 = create_df_subset(df_RE_latlongs2021, df_EssentialLatLong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arts</th>\n",
       "      <th>Elem_School</th>\n",
       "      <th>Golf</th>\n",
       "      <th>Gym</th>\n",
       "      <th>High_School</th>\n",
       "      <th>Historic</th>\n",
       "      <th>ISU</th>\n",
       "      <th>Library</th>\n",
       "      <th>Medical</th>\n",
       "      <th>Movies</th>\n",
       "      <th>Organic_Groceries</th>\n",
       "      <th>Park</th>\n",
       "      <th>Recreation</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Shopping</th>\n",
       "      <th>Spa</th>\n",
       "      <th>Sports_Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[633.8, 6846.7]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[[340.5, 4066.3]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[131.1, 1488.6]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[288.4, 3129.8]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[504.8, 5289.6]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25943</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[282.9, 4091.9]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25945</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[363.9, 4665.5]]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25947</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[637.1, 7927.1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25949</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[375.7, 4907.1]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25951</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[385.3, 4985.1]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11394 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Arts        Elem_School               Golf  \\\n",
       "1      [[633.8, 6846.7]]                NaN                NaN   \n",
       "3                    NaN  [[340.5, 4066.3]]                NaN   \n",
       "7                    NaN                NaN  [[131.1, 1488.6]]   \n",
       "10                   NaN                NaN                NaN   \n",
       "12                   NaN                NaN                NaN   \n",
       "...                  ...                ...                ...   \n",
       "25943                NaN                NaN                NaN   \n",
       "25945                NaN                NaN                NaN   \n",
       "25947                NaN                NaN                NaN   \n",
       "25949                NaN                NaN                NaN   \n",
       "25951                NaN                NaN                NaN   \n",
       "\n",
       "                     Gym        High_School Historic  ISU Library Medical  \\\n",
       "1                    NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "3                    NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "7                    NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "10     [[288.4, 3129.8]]                NaN      NaN  NaN     NaN     NaN   \n",
       "12                   NaN  [[504.8, 5289.6]]      NaN  NaN     NaN     NaN   \n",
       "...                  ...                ...      ...  ...     ...     ...   \n",
       "25943                NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "25945                NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "25947                NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "25949                NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "25951                NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "\n",
       "      Movies  Organic_Groceries Park Recreation Religion         Restaurant  \\\n",
       "1        NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "3        NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "7        NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "10       NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "12       NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "...      ...                ...  ...        ...      ...                ...   \n",
       "25943    NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "25945    NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "25947    NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "25949    NaN                NaN  NaN        NaN      NaN  [[375.7, 4907.1]]   \n",
       "25951    NaN  [[385.3, 4985.1]]  NaN        NaN      NaN                NaN   \n",
       "\n",
       "                Shopping                Spa       Sports_Venue  \n",
       "1                    NaN                NaN                NaN  \n",
       "3                    NaN                NaN                NaN  \n",
       "7                    NaN                NaN                NaN  \n",
       "10                   NaN                NaN                NaN  \n",
       "12                   NaN                NaN                NaN  \n",
       "...                  ...                ...                ...  \n",
       "25943  [[282.9, 4091.9]]                NaN                NaN  \n",
       "25945                NaN  [[363.9, 4665.5]]                NaN  \n",
       "25947                NaN                NaN  [[637.1, 7927.1]]  \n",
       "25949                NaN                NaN                NaN  \n",
       "25951                NaN                NaN                NaN  \n",
       "\n",
       "[11394 rows x 18 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating from_biz_final\n",
    "from_biz_final2021 = drive_time_dist_lookups(df_subset2021)\n",
    "from_biz_final2021\n",
    "\n",
    "#save_state_pkl('from_biz_api2021', from_biz_final2021, \"Adding 2021 services driving times/distances lookups from OSMR \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating driv_final_dict\n",
    "driv_final_dict2021 = create_driv_time_final_dict(from_biz_final2021, df_subset2021, df_RE_latlongs2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating final output dataframe for feature engineering to store in Ames_notebook_state pkl file\n",
    "df_for_feature_engineering2021 = create_df_for_feature_engineering(driv_final_dict2021, df_subset2021)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating 2019 dfs after API drive time/distance lookups in preparation for feature engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating df_subset\n",
    "df_subset2019 = create_df_subset(df_RE_latlongs2019, df_EssentialLatLong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arts</th>\n",
       "      <th>Elem_School</th>\n",
       "      <th>Golf</th>\n",
       "      <th>Gym</th>\n",
       "      <th>High_School</th>\n",
       "      <th>Historic</th>\n",
       "      <th>ISU</th>\n",
       "      <th>Library</th>\n",
       "      <th>Medical</th>\n",
       "      <th>Movies</th>\n",
       "      <th>Organic_Groceries</th>\n",
       "      <th>Park</th>\n",
       "      <th>Recreation</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Shopping</th>\n",
       "      <th>Spa</th>\n",
       "      <th>Sports_Venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[675.6, 8106.8]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>[[440.1, 4269.8]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[389.7, 2898.7]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[441.3, 3925.6]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[656.6, 7138.7]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36931</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[72.8, 717.2]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36933</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[153.8, 1290.8]]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36935</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[427.6, 3961.7]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36937</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[165.6, 1532.4]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36939</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[175.2, 1610.3]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16218 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Arts        Elem_School               Golf  \\\n",
       "2      [[675.6, 8106.8]]                NaN                NaN   \n",
       "3                    NaN  [[440.1, 4269.8]]                NaN   \n",
       "7                    NaN                NaN  [[389.7, 2898.7]]   \n",
       "10                   NaN                NaN                NaN   \n",
       "12                   NaN                NaN                NaN   \n",
       "...                  ...                ...                ...   \n",
       "36931                NaN                NaN                NaN   \n",
       "36933                NaN                NaN                NaN   \n",
       "36935                NaN                NaN                NaN   \n",
       "36937                NaN                NaN                NaN   \n",
       "36939                NaN                NaN                NaN   \n",
       "\n",
       "                     Gym        High_School Historic  ISU Library Medical  \\\n",
       "2                    NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "3                    NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "7                    NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "10     [[441.3, 3925.6]]                NaN      NaN  NaN     NaN     NaN   \n",
       "12                   NaN  [[656.6, 7138.7]]      NaN  NaN     NaN     NaN   \n",
       "...                  ...                ...      ...  ...     ...     ...   \n",
       "36931                NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "36933                NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "36935                NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "36937                NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "36939                NaN                NaN      NaN  NaN     NaN     NaN   \n",
       "\n",
       "      Movies  Organic_Groceries Park Recreation Religion         Restaurant  \\\n",
       "2        NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "3        NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "7        NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "10       NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "12       NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "...      ...                ...  ...        ...      ...                ...   \n",
       "36931    NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "36933    NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "36935    NaN                NaN  NaN        NaN      NaN                NaN   \n",
       "36937    NaN                NaN  NaN        NaN      NaN  [[165.6, 1532.4]]   \n",
       "36939    NaN  [[175.2, 1610.3]]  NaN        NaN      NaN                NaN   \n",
       "\n",
       "              Shopping                Spa       Sports_Venue  \n",
       "2                  NaN                NaN                NaN  \n",
       "3                  NaN                NaN                NaN  \n",
       "7                  NaN                NaN                NaN  \n",
       "10                 NaN                NaN                NaN  \n",
       "12                 NaN                NaN                NaN  \n",
       "...                ...                ...                ...  \n",
       "36931  [[72.8, 717.2]]                NaN                NaN  \n",
       "36933              NaN  [[153.8, 1290.8]]                NaN  \n",
       "36935              NaN                NaN  [[427.6, 3961.7]]  \n",
       "36937              NaN                NaN                NaN  \n",
       "36939              NaN                NaN                NaN  \n",
       "\n",
       "[16218 rows x 18 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating from_biz_final\n",
    "from_biz_final2019 = drive_time_dist_lookups(df_subset2019)\n",
    "from_biz_final2019\n",
    "\n",
    "#save_state_pkl('from_biz_api2019', from_biz_final2019, \"Adding 2019 services driving times/distances lookups from OSMR \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating driv_final_dict\n",
    "driv_final_dict2019 = create_driv_time_final_dict(from_biz_final2019, df_subset2019, df_RE_latlongs2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating final output dataframe for feature engineering to store in Ames_notebook_state pkl file\n",
    "df_for_feature_engineering2019 = create_df_for_feature_engineering(driv_final_dict2019, df_subset2019)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Notebook Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_state_pkl(\"2019dfs_for_feature_engineering\",\n",
    "               df_for_feature_engineering2019,\n",
    "               \"After data transformation of the driving time/distance API results in preparation for feature engineering. Also includes business information and point to point distances.\"\n",
    "                )\n",
    "\n",
    "save_state_pkl(\"2021dfs_for_feature_engineering\",\n",
    "               df_for_feature_engineering2021,\n",
    "               \"After data transformation of the driving time/distance API results in preparation for feature engineering. Also includes business information and point to point distances.\"\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
